{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cdb4187",
   "metadata": {},
   "source": [
    "# Agent Demo - Multi-Agent Educational Tutor System\n",
    "\n",
    "This notebook demonstrates the multi-agent system for educational tutoring:\n",
    "1. **TutorAgent**: Provides explanations and educational content\n",
    "2. **QuizAgent**: Generates quiz questions\n",
    "3. **EvaluatorAgent**: Evaluates explanations and quizzes using LLM-as-judge\n",
    "\n",
    "We'll demonstrate a complete flow: explanation → quiz generation → evaluation → memory storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path to import from src directory\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f485b1-bbc9-4c71-b73e-6b3b6f7d3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "project_root = Path().resolve().parent if Path().resolve().name == 'notebooks' else Path().resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import framework and agents\n",
    "from src.agent_framework import Coordinator\n",
    "from src.agents import TutorAgent\n",
    "from src.memory import MemoryStore, initialize_demo_user_memory\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=project_root / '.env')\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ GEMINI_API_KEY configured: {os.getenv('GEMINI_API_KEY') is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0179db7b",
   "metadata": {},
   "source": [
    "## Step 1: Agent Registration\n",
    "\n",
    "We'll create and register three agents:\n",
    "- **TutorAgent**: For generating explanations\n",
    "- **QuizAgent**: For creating quiz questions (stub implementation)\n",
    "- **EvaluatorAgent**: For evaluating content quality (stub implementation)\n",
    "\n",
    "The Coordinator manages communication between these agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stub QuizAgent (to be fully implemented later)\n",
    "from src.agent_framework import Agent\n",
    "from typing import Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4510ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuizAgent(Agent):\n",
    "    \"\"\"Stub implementation of QuizAgent for demonstration.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"quiz_agent\"):\n",
    "        super().__init__(name=name)\n",
    "        # In full implementation, this would initialize Gemini API\n",
    "    \n",
    "    def handle_message(self, message: Dict[str, Any], context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "        action = message.get(\"action\", \"unknown\")\n",
    "        payload = message.get(\"payload\", {})\n",
    "        request_id = message.get(\"request_id\", \"unknown\")\n",
    "        \n",
    "        if action == \"generate_quiz\":\n",
    "            topic = payload.get(\"topic\", \"\")\n",
    "            difficulty = payload.get(\"difficulty\", \"intermediate\")\n",
    "            n_questions = payload.get(\"n_questions\", 5)\n",
    "            \n",
    "            # Stub response - in full implementation, this would call Gemini API\n",
    "            return {\n",
    "                \"status\": \"ok\",\n",
    "                \"payload\": {\n",
    "                    \"questions\": [\n",
    "                        {\n",
    "                            \"id\": f\"q{i+1}\",\n",
    "                            \"question\": f\"Sample question {i+1} about {topic}\",\n",
    "                            \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"],\n",
    "                            \"correct_answer\": \"Option A\",\n",
    "                            \"answer_index\": 0,\n",
    "                            \"explanation\": f\"Explanation for question {i+1}\"\n",
    "                        }\n",
    "                        for i in range(n_questions)\n",
    "                    ],\n",
    "                    \"topic\": topic,\n",
    "                    \"difficulty\": difficulty\n",
    "                },\n",
    "                \"request_id\": request_id,\n",
    "                \"meta\": {\"agent\": self.name}\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"payload\": {\"error\": f\"Unknown action: {action}\"},\n",
    "                \"request_id\": request_id,\n",
    "                \"meta\": {\"agent\": self.name}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6279a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatorAgent(Agent):\n",
    "    \"\"\"Stub implementation of EvaluatorAgent for demonstration.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"evaluator_agent\"):\n",
    "        super().__init__(name=name)\n",
    "        # In full implementation, this would initialize Gemini API\n",
    "    \n",
    "    def handle_message(self, message: Dict[str, Any], context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "        action = message.get(\"action\", \"unknown\")\n",
    "        payload = message.get(\"payload\", {})\n",
    "        request_id = message.get(\"request_id\", \"unknown\")\n",
    "        \n",
    "        if action == \"evaluate\":\n",
    "            source_text = payload.get(\"source_text\", \"\")\n",
    "            candidate = payload.get(\"candidate\", \"\")\n",
    "            \n",
    "            # Stub response - in full implementation, this would call Gemini API with EVALUATOR_PROMPT\n",
    "            return {\n",
    "                \"status\": \"ok\",\n",
    "                \"payload\": {\n",
    "                    \"accuracy_score\": 4,\n",
    "                    \"clarity_score\": 5,\n",
    "                    \"completeness_score\": 4,\n",
    "                    \"usefulness_score\": 5,\n",
    "                    \"overall_score\": 4.5,\n",
    "                    \"hallucinated_claims\": [],\n",
    "                    \"strengths\": [\"Clear explanation\", \"Good examples\"],\n",
    "                    \"weaknesses\": [\"Could be more detailed\"],\n",
    "                    \"recommendations\": [\"Add more examples\"]\n",
    "                },\n",
    "                \"request_id\": request_id,\n",
    "                \"meta\": {\"agent\": self.name}\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"payload\": {\"error\": f\"Unknown action: {action}\"},\n",
    "                \"request_id\": request_id,\n",
    "                \"meta\": {\"agent\": self.name}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create coordinator\n",
    "coordinator = Coordinator(timeout=60.0)\n",
    "\n",
    "# Create and register agents\n",
    "tutor_agent = TutorAgent(name=\"tutor_agent\")\n",
    "quiz_agent = QuizAgent(name=\"quiz_agent\")\n",
    "evaluator_agent = EvaluatorAgent(name=\"evaluator_agent\")\n",
    "\n",
    "coordinator.register(tutor_agent)\n",
    "coordinator.register(quiz_agent)\n",
    "coordinator.register(evaluator_agent)\n",
    "\n",
    "print(\"✓ Coordinator created\")\n",
    "print(\"✓ Agents registered:\")\n",
    "for agent_name in coordinator.list_agents():\n",
    "    print(f\"  - {agent_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f240034",
   "metadata": {},
   "source": [
    "## Step 2: Request Explanation\n",
    "\n",
    "We'll ask the TutorAgent to explain \"bias-variance tradeoff\" at intermediate level.\n",
    "This demonstrates the core tutoring capability of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request explanation from TutorAgent\n",
    "explain_message = {\n",
    "    \"action\": \"explain\",\n",
    "    \"payload\": {\n",
    "        \"topic\": \"bias-variance tradeoff\",\n",
    "        \"level\": \"intermediate\"\n",
    "    },\n",
    "    \"request_id\": \"explain-001\"\n",
    "}\n",
    "\n",
    "print(\"Requesting explanation from TutorAgent...\")\n",
    "print(f\"Topic: {explain_message['payload']['topic']}\")\n",
    "print(f\"Level: {explain_message['payload']['level']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99703ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_response = coordinator.send(\n",
    "    from_agent=\"tutor_agent\",\n",
    "    to_agent=\"tutor_agent\",\n",
    "    message=explain_message\n",
    ")\n",
    "\n",
    "if explain_response[\"status\"] == \"ok\":\n",
    "    explanation = explain_response[\"payload\"]\n",
    "    print(\"✓ Explanation received successfully\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXPLANATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\n{explanation.get('summary', 'N/A')}\\n\")\n",
    "    \n",
    "    print(\"Step-by-step breakdown:\")\n",
    "    for i, step in enumerate(explanation.get('step_by_step', [])[:5], 1):\n",
    "        print(f\"  {i}. {step}\")\n",
    "    \n",
    "    print(f\"\\nKey equations: {len(explanation.get('key_equations', []))} found\")\n",
    "    print(f\"Examples provided: {len(explanation.get('examples', []))}\")\n",
    "    print(f\"Confidence: {explanation.get('confidence', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"✗ Error: {explain_response['payload']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed7ded",
   "metadata": {},
   "source": [
    "## Step 3: Generate Quiz Questions\n",
    "\n",
    "After receiving the explanation, we'll ask the QuizAgent to generate quiz questions\n",
    "on the same topic to test understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate quiz based on the explanation\n",
    "quiz_message = {\n",
    "    \"action\": \"generate_quiz\",\n",
    "    \"payload\": {\n",
    "        \"topic\": \"bias-variance tradeoff\",\n",
    "        \"difficulty\": \"intermediate\",\n",
    "        \"n_questions\": 5\n",
    "    },\n",
    "    \"request_id\": \"quiz-001\"\n",
    "}\n",
    "\n",
    "print(\"Requesting quiz generation from QuizAgent...\")\n",
    "print(f\"Topic: {quiz_message['payload']['topic']}\")\n",
    "print(f\"Number of questions: {quiz_message['payload']['n_questions']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988966e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_response = coordinator.send(\n",
    "    from_agent=\"tutor_agent\",\n",
    "    to_agent=\"quiz_agent\",\n",
    "    message=quiz_message\n",
    ")\n",
    "\n",
    "if quiz_response[\"status\"] == \"ok\":\n",
    "    quiz_data = quiz_response[\"payload\"]\n",
    "    questions = quiz_data.get(\"questions\", [])\n",
    "    print(f\"✓ Quiz generated successfully: {len(questions)} questions\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"QUIZ QUESTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, q in enumerate(questions[:3], 1):  # Show first 3 questions\n",
    "        print(f\"\\nQuestion {i}: {q.get('question', 'N/A')}\")\n",
    "        if 'options' in q:\n",
    "            for j, opt in enumerate(q['options'], 1):\n",
    "                marker = \"✓\" if j-1 == q.get('answer_index', -1) else \" \"\n",
    "                print(f\"  {marker} {chr(64+j)}. {opt}\")\n",
    "        print(f\"  Explanation: {q.get('explanation', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"✗ Error: {quiz_response['payload']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e6be6",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Explanation Quality\n",
    "\n",
    "We'll use the EvaluatorAgent (LLM-as-judge) to evaluate the quality of the explanation\n",
    "we received. This demonstrates automatic quality assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the explanation using EvaluatorAgent\n",
    "# In a real scenario, we'd compare against source material\n",
    "source_text = \"Bias-variance tradeoff is a fundamental concept in machine learning...\"\n",
    "\n",
    "evaluate_message = {\n",
    "    \"action\": \"evaluate\",\n",
    "    \"payload\": {\n",
    "        \"source_text\": source_text,\n",
    "        \"candidate\": explanation.get(\"summary\", \"\") + \"\\n\" + \"\\n\".join(explanation.get(\"step_by_step\", []))\n",
    "    },\n",
    "    \"request_id\": \"eval-001\"\n",
    "}\n",
    "\n",
    "print(\"Requesting evaluation from EvaluatorAgent...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_response = coordinator.send(\n",
    "    from_agent=\"tutor_agent\",\n",
    "    to_agent=\"evaluator_agent\",\n",
    "    message=evaluate_message\n",
    ")\n",
    "\n",
    "if eval_response[\"status\"] == \"ok\":\n",
    "    evaluation = eval_response[\"payload\"]\n",
    "    print(\"✓ Evaluation completed successfully\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nAccuracy Score: {evaluation.get('accuracy_score', 'N/A')}/5\")\n",
    "    print(f\"Clarity Score: {evaluation.get('clarity_score', 'N/A')}/5\")\n",
    "    print(f\"Completeness Score: {evaluation.get('completeness_score', 'N/A')}/5\")\n",
    "    print(f\"Usefulness Score: {evaluation.get('usefulness_score', 'N/A')}/5\")\n",
    "    print(f\"Overall Score: {evaluation.get('overall_score', 'N/A')}/5\")\n",
    "    \n",
    "    strengths = evaluation.get('strengths', [])\n",
    "    if strengths:\n",
    "        print(f\"\\nStrengths:\")\n",
    "        for strength in strengths:\n",
    "            print(f\"  ✓ {strength}\")\n",
    "    \n",
    "    weaknesses = evaluation.get('weaknesses', [])\n",
    "    if weaknesses:\n",
    "        print(f\"\\nWeaknesses:\")\n",
    "        for weakness in weaknesses:\n",
    "            print(f\"  - {weakness}\")\n",
    "else:\n",
    "    print(f\"✗ Error: {eval_response['payload']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597bb25",
   "metadata": {},
   "source": [
    "## Step 5: Save Results to Memory\n",
    "\n",
    "We'll save the explanation, quiz, and evaluation results to the memory store\n",
    "for future reference and to track user progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ddd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory store\n",
    "memory_store = MemoryStore(storage_path=str(project_root / \"data\" / \"memory_store.json\"))\n",
    "\n",
    "# Save explanation\n",
    "memory_store.save(\"session:001:explanation\", {\n",
    "    \"topic\": \"bias-variance tradeoff\",\n",
    "    \"level\": \"intermediate\",\n",
    "    \"explanation\": explanation,\n",
    "    \"timestamp\": memory_store._get_timestamp(),\n",
    "    \"tags\": [\"explanation\", \"bias-variance\", \"intermediate\"]\n",
    "})\n",
    "\n",
    "# Save quiz\n",
    "memory_store.save(\"session:001:quiz\", {\n",
    "    \"topic\": \"bias-variance tradeoff\",\n",
    "    \"quiz_data\": quiz_data,\n",
    "    \"timestamp\": memory_store._get_timestamp(),\n",
    "    \"tags\": [\"quiz\", \"bias-variance\", \"intermediate\"]\n",
    "})\n",
    "\n",
    "# Save evaluation\n",
    "memory_store.save(\"session:001:evaluation\", {\n",
    "    \"topic\": \"bias-variance tradeoff\",\n",
    "    \"evaluation\": evaluation,\n",
    "    \"timestamp\": memory_store._get_timestamp(),\n",
    "    \"tags\": [\"evaluation\", \"bias-variance\"]\n",
    "})\n",
    "\n",
    "# Save session summary\n",
    "memory_store.save(\"session:001:summary\", {\n",
    "    \"session_id\": \"001\",\n",
    "    \"topic\": \"bias-variance tradeoff\",\n",
    "    \"actions\": [\"explain\", \"generate_quiz\", \"evaluate\"],\n",
    "    \"timestamp\": memory_store._get_timestamp(),\n",
    "    \"tags\": [\"session\", \"bias-variance\"]\n",
    "})\n",
    "\n",
    "print(\"✓ Results saved to memory store\\n\")\n",
    "print(\"=\" * 60)\n",
    "print(\"MEMORY STORAGE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4366c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved data\n",
    "saved_explanation = memory_store.load(\"session:001:explanation\")\n",
    "saved_quiz = memory_store.load(\"session:001:quiz\")\n",
    "saved_eval = memory_store.load(\"session:001:evaluation\")\n",
    "\n",
    "print(f\"\\n✓ Explanation saved: {saved_explanation is not None}\")\n",
    "print(f\"✓ Quiz saved: {saved_quiz is not None}\")\n",
    "print(f\"✓ Evaluation saved: {saved_eval is not None}\")\n",
    "\n",
    "# Search by tag\n",
    "bias_variance_items = memory_store.search_by_tag(\"bias-variance\")\n",
    "print(f\"\\n✓ Found {len(bias_variance_items)} items tagged 'bias-variance'\")\n",
    "\n",
    "# Close memory store\n",
    "memory_store.close()\n",
    "print(\"\\n✓ Memory store operations completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ffae1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demonstration showed:\n",
    "\n",
    "1. **Multi-Agent Coordination**: Three agents (Tutor, Quiz, Evaluator) working together\n",
    "2. **Explanation Generation**: TutorAgent providing structured explanations\n",
    "3. **Quiz Creation**: QuizAgent generating assessment questions\n",
    "4. **Quality Evaluation**: EvaluatorAgent assessing explanation quality\n",
    "5. **Memory Persistence**: Saving all results for future reference\n",
    "\n",
    "The system demonstrates:\n",
    "- ✅ Agent-to-agent communication via Coordinator\n",
    "- ✅ Structured message passing\n",
    "- ✅ LLM-powered content generation\n",
    "- ✅ Automatic quality assessment\n",
    "- ✅ Persistent memory storage\n",
    "\n",
    "**Next Steps**: \n",
    "- Implement full QuizAgent and EvaluatorAgent with Gemini API\n",
    "- Add SearchAgent for finding educational resources\n",
    "- Integrate with user profiles for personalized tutoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display complete results in JSON format\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPLETE SESSION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = {\n",
    "    \"explanation\": explanation,\n",
    "    \"quiz\": quiz_data,\n",
    "    \"evaluation\": evaluation,\n",
    "    \"session_info\": {\n",
    "        \"session_id\": \"001\",\n",
    "        \"topic\": \"bias-variance tradeoff\",\n",
    "        \"agents_used\": coordinator.list_agents()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(json.dumps(results, indent=2, default=str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
