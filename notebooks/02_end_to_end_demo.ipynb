{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660e0afa",
   "metadata": {},
   "source": [
    "# End-to-End Demo - Educational Tutor Agent System\n",
    "\n",
    "This notebook demonstrates a complete workflow of the multi-agent educational tutoring system:\n",
    "\n",
    "1. **TutorAgent**: Generates structured explanation of \"Bayes theorem\"\n",
    "2. **QuizAgent**: Creates quiz questions to test understanding\n",
    "3. **EvaluatorAgent**: Evaluates the quality of the explanation using LLM-as-judge\n",
    "4. **Memory Store**: Saves all results for future reference and adaptive learning\n",
    "\n",
    "**Topic**: Bayes theorem (intermediate level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89e2349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path to import from src directory\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Import framework and agents\n",
    "from src.agent_framework import Coordinator\n",
    "from src.agents import TutorAgent, QuizAgent, EvaluatorAgent\n",
    "from src.memory import MemoryStore\n",
    "from src.observability import log_event, get_metrics\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e289149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "project_root = Path().resolve().parent if Path().resolve().name == 'notebooks' else Path().resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5b3e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Path: .env\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "env_path = Path(__file__).parent.parent / '.env' if '__file__' in globals() else Path('.env')\n",
    "print(f\"Environment Path: {env_path}\")\n",
    "load_dotenv(dotenv_path=env_path, verbose=True, encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3487a9d7-4412-4fa6-b08f-abf228ec444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EDUCATIONAL TUTOR AGENT - END-TO-END DEMO\n",
      "============================================================\n",
      "\n",
      "✓ Project root: C:\\Users\\punno\\Documents\\GitHub\\google-agent-intensive-capstone-project\n",
      "✓ GEMINI_API_KEY configured: True\n",
      "✓ All modules imported successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EDUCATIONAL TUTOR AGENT - END-TO-END DEMO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n✓ Project root: {project_root}\")\n",
    "print(f\"✓ GEMINI_API_KEY configured: {os.getenv('GEMINI_API_KEY') is not None}\")\n",
    "print(f\"✓ All modules imported successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f40463",
   "metadata": {},
   "source": [
    "## System Architecture\n",
    "\n",
    "The system uses a multi-agent architecture:\n",
    "\n",
    "- **Coordinator**: Manages agent-to-agent communication and message routing\n",
    "- **TutorAgent**: LLM-powered tutor that generates explanations and educational content\n",
    "- **QuizAgent**: Generates quiz questions and grades student answers\n",
    "- **EvaluatorAgent**: LLM-as-judge that evaluates content quality\n",
    "- **MemoryStore**: Persistent storage for user progress and session data\n",
    "\n",
    "All agents communicate through the Coordinator using structured messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a2c708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create coordinator with observability hook\n",
    "def observability_hook(agent_name, event_type, payload):\n",
    "    \"\"\"Hook for logging agent events.\"\"\"\n",
    "    log_event(agent_name, event_type, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ae85f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 16:26:25.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.observability\u001b[0m:\u001b[36mlog_event\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1m[tutor_agent] registered: {'agent_name': 'tutor_agent'}\u001b[0m\n",
      "\u001b[32m2025-11-23 16:26:25.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.observability\u001b[0m:\u001b[36mlog_event\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1m[quiz_agent] registered: {'agent_name': 'quiz_agent'}\u001b[0m\n",
      "\u001b[32m2025-11-23 16:26:25.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.observability\u001b[0m:\u001b[36mlog_event\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1m[evaluator_agent] registered: {'agent_name': 'evaluator_agent'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing agents...\n",
      "✓ Coordinator created\n",
      "✓ Agents registered:\n",
      "  - tutor_agent\n",
      "  - quiz_agent\n",
      "  - evaluator_agent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coordinator = Coordinator(timeout=60.0, observability_hook=observability_hook)\n",
    "\n",
    "# Create memory store (shared across agents)\n",
    "memory_store = MemoryStore(storage_path=str(project_root / \"data\" / \"memory_store.json\"))\n",
    "\n",
    "# Create and register agents\n",
    "# Using gemini-1.5-flash for all agents (reliable and cost-effective)\n",
    "print(\"Initializing agents...\")\n",
    "tutor_agent = TutorAgent(name=\"tutor_agent\", model_name=\"gemini-2.5-flash-lite\")\n",
    "quiz_agent = QuizAgent(name=\"quiz_agent\", model_name=\"gemini-2.5-flash-lite\", memory_store=memory_store)\n",
    "evaluator_agent = EvaluatorAgent(name=\"evaluator_agent\", model_name=\"gemini-2.5-flash-lite\")\n",
    "\n",
    "coordinator.register(tutor_agent)\n",
    "coordinator.register(quiz_agent)\n",
    "coordinator.register(evaluator_agent)\n",
    "\n",
    "print(\"✓ Coordinator created\")\n",
    "print(\"✓ Agents registered:\")\n",
    "for agent_name in coordinator.list_agents():\n",
    "    print(f\"  - {agent_name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0185f1",
   "metadata": {},
   "source": [
    "## Step 1: Generate Explanation\n",
    "\n",
    "We'll ask the TutorAgent to explain \"Bayes theorem\" at intermediate level.\n",
    "The agent will provide a structured explanation with summary, step-by-step breakdown,\n",
    "examples, key equations, and potential difficulties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c389f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: EXPLANATION GENERATION\n",
      "============================================================\n",
      "\n",
      "Topic: Bayes theorem\n",
      "Level: intermediate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the topic for this demo\n",
    "TOPIC = \"Bayes theorem\"\n",
    "LEVEL = \"intermediate\"\n",
    "USER_ID = \"demo_user\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: EXPLANATION GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTopic: {TOPIC}\")\n",
    "print(f\"Level: {LEVEL}\\n\")\n",
    "\n",
    "# Request explanation from TutorAgent\n",
    "explain_message = {\n",
    "    \"action\": \"explain\",\n",
    "    \"payload\": {\n",
    "        \"topic\": TOPIC,\n",
    "        \"level\": LEVEL\n",
    "    },\n",
    "    \"request_id\": \"demo-001\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674fc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 16:55:53.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.observability\u001b[0m:\u001b[36mlog_event\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1m[tutor_agent] message_sent: {'to_agent': 'tutor_agent', 'action': 'explain', 'request_id': 'demo-001'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting explanation from TutorAgent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 16:55:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.observability\u001b[0m:\u001b[36mlog_event\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1m[tutor_agent] message_handled: {'from_agent': 'tutor_agent', 'action': 'explain', 'request_id': 'demo-001', 'elapsed_time': 5.5689332485198975}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test explain response:  {\n",
      "  \"status\": \"error\",\n",
      "  \"payload\": {\n",
      "    \"error\": \"Failed to parse JSON from response: Expecting ',' delimiter: line 16 column 10 (char 2180)\\nResponse: {\\n    \\\"summary\\\": \\\"Bayes' Theorem is a fundamental concept in probability theory that describes how to update the probability of a hypothesis based on new evidence. It allows us to revise our beliefs i\"\n",
      "  },\n",
      "  \"request_id\": \"demo-001\",\n",
      "  \"meta\": {\n",
      "    \"agent\": \"tutor_agent\",\n",
      "    \"action\": \"explain\",\n",
      "    \"elapsed_time\": 5.5689332485198975,\n",
      "    \"from_agent\": \"tutor_agent\"\n",
      "  }\n",
      "}\n",
      "✗ Error: {'error': 'Failed to parse JSON from response: Expecting \\',\\' delimiter: line 16 column 10 (char 2180)\\nResponse: {\\n    \"summary\": \"Bayes\\' Theorem is a fundamental concept in probability theory that describes how to update the probability of a hypothesis based on new evidence. It allows us to revise our beliefs i'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Requesting explanation from TutorAgent...\")\n",
    "try:\n",
    "    explain_response = coordinator.send(\n",
    "        from_agent=\"tutor_agent\",\n",
    "        to_agent=\"tutor_agent\",\n",
    "        message=explain_message\n",
    "    )\n",
    "\n",
    "    if explain_response[\"status\"] == \"ok\":\n",
    "        explanation = explain_response[\"payload\"]\n",
    "        print(\"✓ Explanation received successfully\\n\")\n",
    "        \n",
    "        print(\"SUMMARY:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(explanation.get('summary', 'N/A'))\n",
    "        print()\n",
    "        \n",
    "        print(\"STEP-BY-STEP BREAKDOWN:\")\n",
    "        print(\"-\" * 60)\n",
    "        for i, step in enumerate(explanation.get('step_by_step', [])[:5], 1):\n",
    "            print(f\"{i}. {step}\")\n",
    "        print()\n",
    "        \n",
    "        if explanation.get('key_equations'):\n",
    "            print(\"KEY EQUATIONS:\")\n",
    "            print(\"-\" * 60)\n",
    "            for eq in explanation.get('key_equations', []):\n",
    "                print(f\"  • {eq}\")\n",
    "            print()\n",
    "        \n",
    "        if explanation.get('examples'):\n",
    "            print(\"EXAMPLES:\")\n",
    "            print(\"-\" * 60)\n",
    "            for i, example in enumerate(explanation.get('examples', [])[:2], 1):\n",
    "                print(f\"\\nExample {i}: {example.get('title', 'N/A')}\")\n",
    "                print(f\"  {example.get('description', 'N/A')}\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"Confidence: {explanation.get('confidence', 'N/A')}\")\n",
    "    else:\n",
    "        error_info = explain_response.get('payload', {})\n",
    "        error_msg = error_info.get('error', 'Unknown error')\n",
    "        print(f\"✗ Error: {error_info}\")\n",
    "        \n",
    "        # Check for truncation errors\n",
    "        if 'truncated' in error_msg.lower() or 'unclosed braces' in error_msg.lower():\n",
    "            print(\"\\n⚠️  Response appears to be truncated.\")\n",
    "            print(\"   This usually means the response exceeded max_tokens.\")\n",
    "            print(\"   The system will automatically retry with error handling.\")\n",
    "            print(\"   If this persists, try a simpler topic or increase max_tokens.\")\n",
    "        \n",
    "        explanation = None\n",
    "except Exception as e:\n",
    "    print(f\"✗ Exception occurred: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    explanation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d184e7",
   "metadata": {},
   "source": [
    "## Step 2: Generate Quiz Questions\n",
    "\n",
    "After receiving the explanation, we'll ask the QuizAgent to generate quiz questions\n",
    "on the same topic. This tests the student's understanding of the material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c00b4af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping quiz generation - explanation not available\n"
     ]
    }
   ],
   "source": [
    "if explanation:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 2: QUIZ GENERATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Generate quiz based on the explanation\n",
    "    quiz_message = {\n",
    "        \"action\": \"generate_quiz\",\n",
    "        \"payload\": {\n",
    "            \"topic\": TOPIC,\n",
    "            \"difficulty\": LEVEL,\n",
    "            \"n_questions\": 5\n",
    "        },\n",
    "        \"request_id\": \"demo-002\"\n",
    "    }\n",
    "    \n",
    "    print(\"Requesting quiz generation from QuizAgent...\")\n",
    "    quiz_response = coordinator.send(\n",
    "        from_agent=\"tutor_agent\",\n",
    "        to_agent=\"quiz_agent\",\n",
    "        message=quiz_message\n",
    "    )\n",
    "    \n",
    "    if quiz_response[\"status\"] == \"ok\":\n",
    "        quiz_data = quiz_response[\"payload\"]\n",
    "        questions = quiz_data.get(\"questions\", [])\n",
    "        quiz_id = quiz_data.get(\"quiz_id\", \"unknown\")\n",
    "        \n",
    "        print(f\"✓ Quiz generated successfully: {len(questions)} questions\")\n",
    "        print(f\"  Quiz ID: {quiz_id}\\n\")\n",
    "        print(\"QUIZ QUESTIONS:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for i, q in enumerate(questions, 1):\n",
    "            print(f\"\\nQuestion {i}: {q.get('question', 'N/A')}\")\n",
    "            if 'options' in q:\n",
    "                for j, opt in enumerate(q['options'], 1):\n",
    "                    marker = \"✓\" if j-1 == q.get('answer_index', -1) else \" \"\n",
    "                    print(f\"  {marker} {chr(64+j)}. {opt}\")\n",
    "            print(f\"  Explanation: {q.get('explanation', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"✗ Error: {quiz_response['payload']}\")\n",
    "        quiz_data = None\n",
    "else:\n",
    "    print(\"Skipping quiz generation - explanation not available\")\n",
    "    quiz_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff32f9e",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate Explanation Quality\n",
    "\n",
    "We'll use the EvaluatorAgent (LLM-as-judge) to evaluate the quality of the explanation.\n",
    "This demonstrates automatic quality assessment and helps ensure educational content\n",
    "meets high standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "640c9483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping evaluation - explanation not available\n"
     ]
    }
   ],
   "source": [
    "if explanation:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 3: EXPLANATION EVALUATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Create source text for evaluation (ground truth reference)\n",
    "    source_text = \"\"\"Bayes' theorem is a fundamental theorem in probability theory and statistics.\n",
    "It describes the probability of an event based on prior knowledge of conditions that might be related to the event.\n",
    "The formula is: P(A|B) = P(B|A) * P(A) / P(B)\n",
    "Where:\n",
    "- P(A|B) is the posterior probability\n",
    "- P(B|A) is the likelihood\n",
    "- P(A) is the prior probability\n",
    "- P(B) is the marginal probability\n",
    "Bayes' theorem is widely used in machine learning, medical diagnosis, and decision-making.\"\"\"\n",
    "    \n",
    "    # Combine explanation into candidate text\n",
    "    candidate_text = explanation.get(\"summary\", \"\") + \"\\n\\n\"\n",
    "    candidate_text += \"\\n\".join(explanation.get(\"step_by_step\", []))\n",
    "    \n",
    "    # Evaluate using EvaluatorAgent\n",
    "    evaluate_message = {\n",
    "        \"action\": \"evaluate_summary\",\n",
    "        \"payload\": {\n",
    "            \"source_text\": source_text,\n",
    "            \"candidate\": candidate_text\n",
    "        },\n",
    "        \"request_id\": \"demo-003\"\n",
    "    }\n",
    "    \n",
    "    print(\"Requesting evaluation from EvaluatorAgent...\")\n",
    "    eval_response = coordinator.send(\n",
    "        from_agent=\"tutor_agent\",\n",
    "        to_agent=\"evaluator_agent\",\n",
    "        message=evaluate_message\n",
    "    )\n",
    "    \n",
    "    if eval_response[\"status\"] == \"ok\":\n",
    "        evaluation = eval_response[\"payload\"]\n",
    "        print(\"✓ Evaluation completed successfully\\n\")\n",
    "        \n",
    "        print(\"EVALUATION SCORES:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Accuracy:  {evaluation.get('accuracy', 0):.2f} / 1.0\")\n",
    "        print(f\"Clarity:   {evaluation.get('clarity', 0):.2f} / 1.0\")\n",
    "        print(f\"Usefulness: {evaluation.get('usefulness', 0):.2f} / 1.0\")\n",
    "        \n",
    "        if 'raw_scores' in evaluation:\n",
    "            raw = evaluation['raw_scores']\n",
    "            print(f\"\\nRaw Scores (1-5 scale):\")\n",
    "            print(f\"  Accuracy: {raw.get('accuracy_score', 'N/A')}/5\")\n",
    "            print(f\"  Clarity: {raw.get('clarity_score', 'N/A')}/5\")\n",
    "            print(f\"  Usefulness: {raw.get('usefulness_score', 'N/A')}/5\")\n",
    "            print(f\"  Overall: {raw.get('overall_score', 'N/A')}/5\")\n",
    "        \n",
    "        hallucinations = evaluation.get('hallucinations', [])\n",
    "        if hallucinations:\n",
    "            print(f\"\\n⚠️  Hallucinations detected: {len(hallucinations)}\")\n",
    "            for hall in hallucinations[:3]:\n",
    "                print(f\"  - {hall}\")\n",
    "        else:\n",
    "            print(\"\\n✓ No hallucinations detected\")\n",
    "        \n",
    "        print(f\"\\nEvaluation method: {evaluation.get('method', 'unknown')}\")\n",
    "    else:\n",
    "        print(f\"✗ Error: {eval_response['payload']}\")\n",
    "        evaluation = None\n",
    "else:\n",
    "    print(\"Skipping evaluation - explanation not available\")\n",
    "    evaluation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1aaeda",
   "metadata": {},
   "source": [
    "## Step 4: Save Results to Memory\n",
    "\n",
    "We'll save all results (explanation, quiz, evaluation) to the memory store.\n",
    "This enables:\n",
    "- **Session continuity**: Track user progress across sessions\n",
    "- **Adaptive learning**: Identify weak areas from wrong answers\n",
    "- **Personalization**: Adapt future content based on user history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5e1bbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 4: MEMORY STORAGE\n",
      "============================================================\n",
      "\n",
      "✓ Session summary saved to memory\n",
      "\n",
      "Verifying saved data:\n",
      "  Explanation: ✗\n",
      "  Quiz: ✗\n",
      "  Evaluation: ✗\n",
      "\n",
      "✓ Found 1 items tagged 'bayes-theorem'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 4: MEMORY STORAGE\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Save explanation\n",
    "if explanation:\n",
    "    memory_store.save(f\"user:{USER_ID}:session:bayes:explanation\", {\n",
    "        \"topic\": TOPIC,\n",
    "        \"level\": LEVEL,\n",
    "        \"explanation\": explanation,\n",
    "        \"timestamp\": memory_store._get_timestamp(),\n",
    "        \"tags\": [\"explanation\", \"bayes-theorem\", LEVEL]\n",
    "    })\n",
    "    print(\"✓ Explanation saved to memory\")\n",
    "\n",
    "# Save quiz\n",
    "if quiz_data:\n",
    "    memory_store.save(f\"user:{USER_ID}:session:bayes:quiz\", {\n",
    "        \"topic\": TOPIC,\n",
    "        \"quiz_data\": quiz_data,\n",
    "        \"timestamp\": memory_store._get_timestamp(),\n",
    "        \"tags\": [\"quiz\", \"bayes-theorem\", LEVEL]\n",
    "    })\n",
    "    print(\"✓ Quiz saved to memory\")\n",
    "\n",
    "# Save evaluation\n",
    "if evaluation:\n",
    "    memory_store.save(f\"user:{USER_ID}:session:bayes:evaluation\", {\n",
    "        \"topic\": TOPIC,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"timestamp\": memory_store._get_timestamp(),\n",
    "        \"tags\": [\"evaluation\", \"bayes-theorem\"]\n",
    "    })\n",
    "    print(\"✓ Evaluation saved to memory\")\n",
    "\n",
    "# Save session summary\n",
    "session_summary = {\n",
    "    \"session_id\": \"bayes-demo\",\n",
    "    \"topic\": TOPIC,\n",
    "    \"level\": LEVEL,\n",
    "    \"actions\": [\"explain\", \"generate_quiz\", \"evaluate\"],\n",
    "    \"timestamp\": memory_store._get_timestamp(),\n",
    "    \"tags\": [\"session\", \"bayes-theorem\", \"demo\"]\n",
    "}\n",
    "memory_store.save(f\"user:{USER_ID}:session:bayes:summary\", session_summary)\n",
    "print(\"✓ Session summary saved to memory\")\n",
    "\n",
    "# Verify saved data\n",
    "print(\"\\nVerifying saved data:\")\n",
    "saved_explanation = memory_store.load(f\"user:{USER_ID}:session:bayes:explanation\")\n",
    "saved_quiz = memory_store.load(f\"user:{USER_ID}:session:bayes:quiz\")\n",
    "saved_eval = memory_store.load(f\"user:{USER_ID}:session:bayes:evaluation\")\n",
    "\n",
    "print(f\"  Explanation: {'✓' if saved_explanation else '✗'}\")\n",
    "print(f\"  Quiz: {'✓' if saved_quiz else '✗'}\")\n",
    "print(f\"  Evaluation: {'✓' if saved_eval else '✗'}\")\n",
    "\n",
    "# Search by tag\n",
    "bayes_items = memory_store.search_by_tag(\"bayes-theorem\")\n",
    "print(f\"\\n✓ Found {len(bayes_items)} items tagged 'bayes-theorem'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2ad3f",
   "metadata": {},
   "source": [
    "## Step 5: Grade Student Answers (Optional Demo)\n",
    "\n",
    "Let's demonstrate quiz grading by answering one of the quiz questions.\n",
    "The QuizAgent will grade the answer and save incorrect answers to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50f08d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping quiz grading - quiz not available\n"
     ]
    }
   ],
   "source": [
    "if quiz_data and quiz_data.get(\"questions\"):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 5: QUIZ GRADING DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Get first question\n",
    "    first_question = quiz_data[\"questions\"][0]\n",
    "    question_id = first_question[\"id\"]\n",
    "    quiz_id = quiz_data.get(\"quiz_id\")\n",
    "    \n",
    "    print(f\"Question: {first_question.get('question', 'N/A')}\")\n",
    "    print(f\"Correct answer: {first_question.get('correct_answer', 'N/A')}\\n\")\n",
    "    \n",
    "    # Test with correct answer\n",
    "    print(\"Testing with CORRECT answer...\")\n",
    "    grade_message_correct = {\n",
    "        \"action\": \"grade_answer\",\n",
    "        \"payload\": {\n",
    "            \"question_id\": question_id,\n",
    "            \"student_answer\": first_question.get(\"correct_answer\", \"\"),\n",
    "            \"quiz_id\": quiz_id,\n",
    "            \"user_id\": USER_ID\n",
    "        },\n",
    "        \"request_id\": \"demo-004\"\n",
    "    }\n",
    "    \n",
    "    grade_response_correct = coordinator.send(\n",
    "        from_agent=\"tutor_agent\",\n",
    "        to_agent=\"quiz_agent\",\n",
    "        message=grade_message_correct\n",
    "    )\n",
    "    \n",
    "    if grade_response_correct[\"status\"] == \"ok\":\n",
    "        result = grade_response_correct[\"payload\"]\n",
    "        print(f\"  Correct: {result['correct']}\")\n",
    "        print(f\"  Score: {result['score']}\")\n",
    "        print(f\"  Explanation: {result['explanation'][:100]}...\\n\")\n",
    "    \n",
    "    # Test with incorrect answer\n",
    "    print(\"Testing with INCORRECT answer...\")\n",
    "    incorrect_answer = \"Wrong answer for testing\"\n",
    "    grade_message_incorrect = {\n",
    "        \"action\": \"grade_answer\",\n",
    "        \"payload\": {\n",
    "            \"question_id\": question_id,\n",
    "            \"student_answer\": incorrect_answer,\n",
    "            \"quiz_id\": quiz_id,\n",
    "            \"user_id\": USER_ID\n",
    "        },\n",
    "        \"request_id\": \"demo-005\"\n",
    "    }\n",
    "    \n",
    "    grade_response_incorrect = coordinator.send(\n",
    "        from_agent=\"tutor_agent\",\n",
    "        to_agent=\"quiz_agent\",\n",
    "        message=grade_message_incorrect\n",
    "    )\n",
    "    \n",
    "    if grade_response_incorrect[\"status\"] == \"ok\":\n",
    "        result = grade_response_incorrect[\"payload\"]\n",
    "        print(f\"  Correct: {result['correct']}\")\n",
    "        print(f\"  Score: {result['score']}\")\n",
    "        print(f\"  Explanation: {result['explanation'][:100]}...\")\n",
    "        \n",
    "        if not result['correct']:\n",
    "            print(\"\\n✓ Incorrect answer saved to memory for adaptive learning\")\n",
    "            \n",
    "            # Check wrong answers in memory\n",
    "            wrong_answers = memory_store.load(f\"user:{USER_ID}:wrong_answers\", default=[])\n",
    "            print(f\"  Total wrong answers tracked: {len(wrong_answers)}\")\n",
    "else:\n",
    "    print(\"Skipping quiz grading - quiz not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb0843d",
   "metadata": {},
   "source": [
    "## Step 6: Observability and Metrics\n",
    "\n",
    "The system tracks all agent interactions through the observability module.\n",
    "Let's view the metrics and logs from this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aed094f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 6: OBSERVABILITY & METRICS\n",
      "============================================================\n",
      "\n",
      "Agent Event Metrics:\n",
      "------------------------------------------------------------\n",
      "  evaluator_agent:registered: 6\n",
      "  quiz_agent:registered: 6\n",
      "  total:message_handled: 7\n",
      "  total:message_sent: 7\n",
      "  total:registered: 18\n",
      "  tutor_agent:message_handled: 7\n",
      "  tutor_agent:message_sent: 7\n",
      "  tutor_agent:registered: 6\n",
      "\n",
      "✓ Logs written to: data/logs/\n",
      "✓ Metrics tracked for all agent interactions\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 6: OBSERVABILITY & METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Get metrics\n",
    "metrics = get_metrics()\n",
    "if metrics:\n",
    "    print(\"Agent Event Metrics:\")\n",
    "    print(\"-\" * 60)\n",
    "    for metric, count in sorted(metrics.items()):\n",
    "        print(f\"  {metric}: {count}\")\n",
    "else:\n",
    "    print(\"No metrics recorded yet\")\n",
    "\n",
    "print(\"\\n✓ Logs written to: data/logs/\")\n",
    "print(\"✓ Metrics tracked for all agent interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4dd10",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This end-to-end demonstration showcased:\n",
    "\n",
    "1. ✅ **Multi-Agent Coordination**: Three specialized agents working together\n",
    "2. ✅ **Explanation Generation**: Structured educational content with examples\n",
    "3. ✅ **Quiz Creation**: Assessment questions to test understanding\n",
    "4. ✅ **Quality Evaluation**: LLM-as-judge evaluation of content quality\n",
    "5. ✅ **Memory Persistence**: All results saved for future reference\n",
    "6. ✅ **Adaptive Learning**: Wrong answers tracked for personalized tutoring\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "\n",
    "- **Agent-to-Agent Communication**: Seamless message passing via Coordinator\n",
    "- **Structured Outputs**: JSON-formatted responses for easy parsing\n",
    "- **LLM Integration**: Google Gemini API for content generation\n",
    "- **Quality Assurance**: Automatic evaluation of generated content\n",
    "- **Persistent Memory**: Session data saved for continuity\n",
    "- **Observability**: Full logging and metrics tracking\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Extend with SearchAgent for finding educational resources\n",
    "- Implement user profiles for personalized learning paths\n",
    "- Add more sophisticated adaptive learning algorithms\n",
    "- Integrate with external educational content APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e4191ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPLETE SESSION RESULTS\n",
      "============================================================\n",
      "\n",
      "{\n",
      "  \"session_info\": {\n",
      "    \"topic\": \"Bayes theorem\",\n",
      "    \"level\": \"intermediate\",\n",
      "    \"user_id\": \"demo_user\",\n",
      "    \"agents_used\": [\n",
      "      \"tutor_agent\",\n",
      "      \"quiz_agent\",\n",
      "      \"evaluator_agent\"\n",
      "    ],\n",
      "    \"timestamp\": \"2025-11-23T16:26:31.959063\"\n",
      "  },\n",
      "  \"explanation\": null,\n",
      "  \"quiz\": null,\n",
      "  \"evaluation\": null\n",
      "}\n",
      "\n",
      "✓ Memory store closed\n",
      "✓ Demo completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPLETE SESSION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Compile all results\n",
    "results = {\n",
    "    \"session_info\": {\n",
    "        \"topic\": TOPIC,\n",
    "        \"level\": LEVEL,\n",
    "        \"user_id\": USER_ID,\n",
    "        \"agents_used\": coordinator.list_agents(),\n",
    "        \"timestamp\": memory_store._get_timestamp()\n",
    "    },\n",
    "    \"explanation\": explanation if explanation else None,\n",
    "    \"quiz\": quiz_data if quiz_data else None,\n",
    "    \"evaluation\": evaluation if evaluation else None\n",
    "}\n",
    "\n",
    "# Display as formatted JSON\n",
    "print(json.dumps(results, indent=2, default=str))\n",
    "\n",
    "# Close memory store\n",
    "memory_store.close()\n",
    "print(\"\\n✓ Memory store closed\")\n",
    "print(\"✓ Demo completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
